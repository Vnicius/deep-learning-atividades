{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em um problema real de Redes Neurais, normalmente uma instância pode possuir inúmeras entradas, resultando em uma arquitetura de rede extensa com muitos neurônios e de múltiplas camadas. \n",
    "\n",
    "Um exemplo comum de aplicação nesse escopo é um classificador de imagens, em que cada entrada representa um neurônio da camada de entrada. Sabendo disso, esse notebook tem como objetivo implementar uma Rede Neural Multicamada (MLP) para o dataset MNIST. O MNIST é um dataset de dígitos escritos a mão, conforme Figura 1. \n",
    "\n",
    "A MLP deve ser implementada de forma a utilizar uma arquitetura simples e ainda, assim, obter uma performance elevada. Ao final, três modelos de rede devem ser implementados e comparados. Os detalhes de implementação devem ser justificados a cada questão e será dividido em 5 etapas:\n",
    "* Leitura, visualização e Préprocessamento do dataset\n",
    "* Conversão do array de predições Y\n",
    "* Definição da topologia da rede (camadas e neurônios)\n",
    "* Definir otimizador, função custo e modo do treinamento (batch, mini-batch, estocástico)\n",
    "* Treinamento e avaliação de resultados\n",
    "\n",
    "![alt text](imgs/mninst.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura, visualização e pré-processamento do dataset\n",
    "\n",
    "Ao utilizar Redes Neurais para imagens, cada entrada é um pixel. Dessa forma, após a leitura do dataset, precisa-se descobrir as dimensões da imagem, a quantidade de instâncias, quantas classes e entradas são necessárias para o problema.\n",
    "\n",
    "Feito isso, algumas técnicas de pré-processamento devem ser utilizadas para melhores resultados, dentre eles converter a imagem para tons de cinza e normalizar.\n",
    "\n",
    "Sabendo disso, retorne na célula abaixo essas informações e gere uma versão normalizada do dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### leitura do dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "### Visualizar instâncias\n",
    "plt.imshow(x_train[5], cmap=plt.get_cmap('gray'))\n",
    "plt.title(y_train[5])\n",
    "### Print - informações das instâncias\n",
    "num_classes = 10\n",
    "### Normalizar\n",
    "x_train = x_train.reshape(60000,784).astype('float32') / 255\n",
    "x_test =  x_test.reshape(10000,784).astype('float32') / 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversão do array de predições Y\n",
    "\n",
    "Baseado no número de classes do problema, represente a saída como one-hot encoding. Indique a importância dessa representação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(true_labels,num_classes):\n",
    "    \"\"\"\n",
    "    Função que implementa o one-hot encoding\n",
    "    Entrada: true_labels - array original com os labels\n",
    "    Retorna: labels - conversão one-hot          \n",
    "    \"\"\"\n",
    "    labels = keras.utils.to_categorical(true_labels, num_classes)\n",
    "    return labels\n",
    "\n",
    "y_train_oh = one_hot(y_train, num_classes)\n",
    "y_test_oh = one_hot(y_test, num_classes)\n",
    "\n",
    "#print(x_train[5])\n",
    "#print(y_train_oh[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição de Topologia da Rede\n",
    "\n",
    "Mostre as três arquiteturas que serão utilizadas para resolver o problema. As arquiteturas devem ser simples de forma a retornar bons resultados com a menor quantidade necessária de neurônios e camadas. As três arquiteturas devem variar apenas quanto ao número de neurônios e camadas (incluindo regularização). Baseado nisso, explique:\n",
    "* Quantos neurônios serão utilizados em cada camada?\n",
    "* Quantas camadas serão utilizadas?\n",
    "* É necessário utilizar regularização? Se sim explique a técnica que foi utilizada e o impacto nos resultados\n",
    "* Qual função de ativação será utilizada? Escolha duas funções de ativação e explique os resultados obtidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_56 to have shape (10,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-dbe1ddbc0594>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\agoravai\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\agoravai\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1635\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1636\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1637\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1638\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\agoravai\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1485\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1487\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1488\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1489\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\agoravai\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_56 to have shape (10,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir otimizador, função custo e modo do treinamento\n",
    "\n",
    "Uma Rede Neural é um problema de otimização, sabendo disso, explique:\n",
    "* Qual otimizador será utilizado? Escolha dois otimizadores, explique a diferença entre eles justificando a escolha e comente os resultados obtidos.\n",
    "* Será necessário utilizar uma função custo? Explique o que é uma função custo e qual será utilizada justificando a escolha.\n",
    "* Qual modo de treinamento foi utilizado? Justifique sua resposta\n",
    "* Quantas épocas serão necessárias? Caso os métodos por batch ou mini-batch sejam escolhidos, indique também o tamanho\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento e avaliação dos resultados\n",
    "\n",
    "Treine as três redes e mostre os resultados de cada uma a partir das questões anteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
